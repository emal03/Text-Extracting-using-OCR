# -*- coding: utf-8 -*-
"""text_extracting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zyQUXAp1BZdpdi3qI0yhNoGuEpI1sGkS
"""

import os
import boto3
import pandas as pd

# Set environment variables for AWS keys
os.environ["AWS_ACCESS_KEY_ID"] = ""
os.environ["AWS_SECRET_ACCESS_KEY"] = ""
os.environ["AWS_REGION"] = "us-east-1"  # Replace with your AWS region

# Verify environment variables
print("Access Key ID:", os.getenv("AWS_ACCESS_KEY_ID"))
print("AWS Region:", os.getenv("AWS_REGION"))

# Initialize S3 client
s3_client = boto3.client(
    "s3",
    aws_access_key_id=os.getenv("AWS_ACCESS_KEY_ID"),
    aws_secret_access_key=os.getenv("AWS_SECRET_ACCESS_KEY"),
    region_name=os.getenv("AWS_REGION")
)

# Initialize Textract client
textract_client = boto3.client(
    "textract",
    aws_access_key_id=os.getenv("AWS_ACCESS_KEY_ID"),
    aws_secret_access_key=os.getenv("AWS_SECRET_ACCESS_KEY"),
    region_name=os.getenv("AWS_REGION")
)

# Function to list S3 buckets
def list_s3_buckets():
    try:
        response = s3_client.list_buckets()
        print("S3 Buckets:", response["Buckets"])
    except Exception as e:
        print("Error listing S3 buckets:", e)

# Function to analyze a document with Textract
def analyze_document(bucket_name, document_name):
    try:
        response = textract_client.analyze_document(
            Document={
                'S3Object': {
                    'Bucket': bucket_name,
                    'Name': document_name
                }
            },
            FeatureTypes=["TABLES", "FORMS"]
        )
        print("Textract response received successfully.")
        return response
    except Exception as e:
        print("Error analyzing document:", e)

# Function to parse Textract response and extract text
def parse_textract_response(response):
    lines = []
    for block in response['Blocks']:
        if block['BlockType'] == 'LINE':
            lines.append(block['Text'])
    print("Extracted Text:", "\n".join(lines))
    return lines

# Function to save extracted data to Excel
def save_to_excel(data, output_file):
    df = pd.DataFrame(data, columns=["Extracted Text"])
    df.to_excel(output_file, index=False)
    print(f"Results saved to {output_file}")

# Main script
if __name__ == "__main__":
    # 1. Test S3 access
    list_s3_buckets()

    # 2. Specify the bucket and document
    bucket_name = ""  # Replace with your bucket name
    document_name = "document.pdf"  # Replace with your document name

    # 3. Analyze the document
    textract_response = analyze_document(bucket_name, document_name)

    if textract_response:
        # 4. Parse the Textract response
        extracted_lines = parse_textract_response(textract_response)

        # 5. Save the results to Excel
        output_excel = "textract_output.xlsx"
        save_to_excel([[line] for line in extracted_lines], output_excel)

# Install required libraries
!pip install boto3 pandas openpyxl

# Import required libraries
import os
import boto3
import pandas as pd
import re
import time
from google.colab import files

# Set AWS credentials and region
os.environ["AWS_ACCESS_KEY_ID"] = ""
os.environ["AWS_SECRET_ACCESS_KEY"] = ""
os.environ["AWS_REGION"] = "ap-south-1"

# Initialize Textract client
textract_client = boto3.client("textract", region_name=os.getenv("AWS_REGION"))

# Function to upload the file to S3
def upload_to_s3(file_path, bucket_name, object_name):
    try:
        s3_client = boto3.client("s3")
        s3_client.upload_file(file_path, bucket_name, object_name)
        print(f"File uploaded to S3 bucket {bucket_name} with key {object_name}")
    except Exception as e:
        print(f"Error uploading file to S3: {e}")
        raise

# Function to start Textract job
def start_textract_job(bucket, key):
    try:
        print(f"Starting Textract job for document: {key}")
        response = textract_client.start_document_analysis(
            DocumentLocation={
                "S3Object": {
                    "Bucket": bucket,
                    "Name": key
                }
            },
            FeatureTypes=["TABLES", "FORMS"]
        )
        job_id = response["JobId"]
        print(f"Textract job started successfully. Job ID: {job_id}")
        return job_id
    except Exception as e:
        print(f"Error starting Textract job: {e}")
        raise

# Function to check Textract job status
def check_textract_job_status(job_id):
    while True:
        response = textract_client.get_document_analysis(JobId=job_id)
        status = response["JobStatus"]
        if status in ["SUCCEEDED", "FAILED"]:
            print(f"Textract job completed with status: {status}")
            return response if status == "SUCCEEDED" else None
        print("Textract job is still in progress...")
        time.sleep(5)

# Function to parse required fields from Textract response
def parse_required_fields(response):
    text_blocks = [block['Text'] for block in response['Blocks'] if block['BlockType'] == 'LINE']
    print("Extracted Text Blocks:")
    for i, line in enumerate(text_blocks):
        print(f"{i+1}: {line}")

    # Initialize variables
    invoice_no = trn_no = date = amount_before_vat = vat_5 = amount_after_vat = None
    structured_data = []

    # Extract data based on patterns
    for i, line in enumerate(text_blocks):
        # Extract Invoice No.
        if "Invoice No" in line or "No." in line:
            match = re.search(r"Invoice No[:\-]?\s*(\S+)|No[:\-]?\s*(\d+)", line)
            if match:
                invoice_no = match.group(1) or match.group(2)

        # Extract TRN No.
        if "TRN" in line:
            match = re.search(r"TRN[:\-]?\s*(\d+)", line)
            if match:
                trn_no = match.group(1)

        # Extract Date
        if "Date" in line:
            match = re.search(r"Date[:\-]?\s*(\d{1,2}/\d{1,2}/\d{2,4}|\d{1,2}-\w{3}-\d{2,4}|\d{1,2}\.\d{1,2}\.\d{2,4})", line)
            if match:
                date = match.group(1)

        # Extract Amount Before VAT
        if "TOTAL BEFORE VAT" in line or "Amount Before VAT" in line:
            match = re.search(r"(\d+\.\d+)", line)
            if match:
                amount_before_vat = match.group(1)

        # Extract VAT 5%
        if "VAT 5%" in line:
            match = re.search(r"VAT 5%[:\-]?\s*(\d+\.\d+)", line)
            if match:
                vat_5 = match.group(1)

        # Extract Amount After VAT
        if "TOTAL" in line or "Invoice Total" in line:
            match = re.search(r"TOTAL[:\-]?\s*(\d+\.\d+)", line)
            if match:
                amount_after_vat = match.group(1)

        # If all fields are populated, save the data and reset
        if invoice_no and trn_no and date and amount_before_vat and vat_5 and amount_after_vat:
            structured_data.append({
                "Invoice No.": invoice_no,
                "TRN No.": trn_no,
                "Date": date,
                "Amount Before VAT": amount_before_vat,
                "VAT 5%": vat_5,
                "Amount After VAT": amount_after_vat
            })
            # Reset for next invoice
            invoice_no = trn_no = date = amount_before_vat = vat_5 = amount_after_vat = None

    return structured_data

# Function to handle the entire process
def process_document(file_path, bucket_name, object_name):
    try:
        # Upload to S3
        upload_to_s3(file_path, bucket_name, object_name)

        # Start Textract job
        job_id = start_textract_job(bucket_name, object_name)

        # Wait for Textract to complete
        textract_response = check_textract_job_status(job_id)
        if not textract_response:
            print("Textract job failed.")
            return

        # Parse required fields
        structured_data = parse_required_fields(textract_response)

        # Display results in Colab
        if structured_data:
            df = pd.DataFrame(structured_data)
            print("Extracted Data:")
            display(df)
        else:
            print("No structured data extracted.")

    except Exception as e:
        print(f"An error occurred during processing: {e}")

# Upload file to Colab and process
print("Upload your file:")
uploaded = files.upload()

# Assuming only one file is uploaded
file_name = list(uploaded.keys())[0]
bucket_name = ""  # Replace with your S3 bucket name
object_name = f"uploaded/{file_name}"  # Replace with desired S3 key structure

# Process the uploaded document
process_document(file_name, bucket_name, object_name)

import pandas as pd

# Path to the Excel file
excel_file_path = "textract_results_structured.xlsx"

# Read and display the Excel file
try:
    df = pd.read_excel(excel_file_path)
    print("Contents of the Excel file:")
    print(df)
except Exception as e:
    print("Error reading the Excel file:", e)

text_blocks = [block['Text'] for block in textract_response['Blocks'] if block['BlockType'] == 'LINE']
print("Extracted Text Blocks:", "\n".join(text_blocks))

